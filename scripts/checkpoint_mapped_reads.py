"""
Calculate minimum number of reads necessary to meet minimum depth for a
reference and determine the number of mapped reads from bowtie2 alignment
summary.

Print both to the <output>.
"""
import argparse
import json
from Bio import SeqIO

def determine_if_all_segments_aligned(bamstats, reference) -> bool:
    """
    Use *bamstats* coverage summary to determine if there is coverage
    for all segments within *reference*.
    """
    ref_segments = set()
    with open(reference, "r") as ref:
        for line in ref:
            if line.startswith(">"):
                ref_segments.add(line.lstrip(">").rstrip("\n"))

    bamstats_segments = set()
    with open(bamstats, "r") as f:
        # try to skip header line
        try:
            next(f)
        except StopIteration as err:
            print("No coverage statistics found in BAMStats log.")
        else:
            for line in f:
                bamstats_segments.add(line.split()[0])

    return ref_segments == bamstats_segments

def determine_ref_genome_length(reference):
    """
    Calculate the genome length of a given *reference*
    """
    genome_length = 0
    for segment in SeqIO.parse(reference, 'fasta'):
        seq = segment.seq
        seq_length = len(seq)
        genome_length += seq_length
    return genome_length


def determine_number_of_mapped_reads(bowtie2):
    """
    Use the given *bowtie2* alignment summary to determine the total number of
    reads that aligned with the reference
    """
    mapped_reads = 0
    with open(bowtie2, "r") as summary:
        for line in summary.readlines():
            if "1 time" not in line:
                continue
            aligned = int(line.split()[0])
            mapped_reads += aligned
    return mapped_reads


def print_results_as_json(all_segments_aligned, minimum_reads, mapped_reads, output_file):
    """
    Print *all_segments_aligned*, *minimum_reads* and *mapped_reads* as JSON
    in provided *output_file*
    """
    checkpoint_summary = {
        "all_segments_aligned": all_segments_aligned,
        "minimum_reads_required": minimum_reads,
        "mapped_reads": mapped_reads
    }
    with open(output_file, "w+") as output:
        json.dump(checkpoint_summary, output)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description = __doc__,
        formatter_class = argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("--bamstats", type=str, required=True,
        help = "Coverage stats generated by BAMStats")
    parser.add_argument("--bowtie2", type=str, required=True,
        help = "Summary log from bowtie2")
    parser.add_argument("--min-cov", type=int, required=True,
        help = "Minimum coverage set for varscan")
    parser.add_argument("--raw-read-length", type=int, required=True,
        help = "Length of raw reads in FASTQ files")
    parser.add_argument("--reference", type=str, required=True,
        help = "Reference FASTA file")
    parser.add_argument("--output", type=str, required=True,
        help = "The output of the checkpoint in Snakemake")

    args = parser.parse_args()

    all_segments_aligned = determine_if_all_segments_aligned(args.bamstats,
                                                             args.reference)
    genome_length = determine_ref_genome_length(args.reference)
    minimum_reads = (genome_length * args.min_cov) / args.raw_read_length
    mapped_reads = determine_number_of_mapped_reads(args.bowtie2)
    print_results_as_json(all_segments_aligned, minimum_reads, mapped_reads, args.output)
